{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a0aa35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import time\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555d8774",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check dataset\n",
    "print(os.listdir(\"./dataset\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5914f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load data\n",
    "data = pd.read_csv(\"./dataset/database.csv\")\n",
    "print(\"Original data shape:\", data.shape)\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b240d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select relevant columns\n",
    "data = data[['Date', 'Time', 'Latitude', 'Longitude', 'Depth', 'Magnitude']]\n",
    "print(\"\\nSelected columns:\")\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f276ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convert Date and Time to Timestamp\n",
    "timestamp = []\n",
    "for d, t in zip(data['Date'], data['Time']):\n",
    "    try:\n",
    "        ts = datetime.datetime.strptime(d+' '+t, '%m/%d/%Y %H:%M:%S')\n",
    "        timestamp.append(time.mktime(ts.timetuple()))\n",
    "    except ValueError:\n",
    "        timestamp.append('ValueError')\n",
    "\n",
    "timeStamp = pd.Series(timestamp)\n",
    "data['Timestamp'] = timeStamp.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fda1648",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Clean data - remove invalid timestamps\n",
    "final_data = data.drop(['Date', 'Time'], axis=1)\n",
    "final_data = final_data[final_data.Timestamp != 'ValueError']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd5602f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Remove any remaining NaN values\n",
    "final_data = final_data.dropna()\n",
    "\n",
    "print(\"\\nCleaned data shape:\", final_data.shape)\n",
    "print(final_data.head())\n",
    "print(\"\\nData types:\")\n",
    "print(final_data.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de9f08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ==================== VISUALIZATION ====================\n",
    "try:\n",
    "    from mpl_toolkits.basemap import Basemap\n",
    "    \n",
    "    longitudes = final_data[\"Longitude\"].tolist()\n",
    "    latitudes = final_data[\"Latitude\"].tolist()\n",
    "    \n",
    "    fig = plt.figure(figsize=(12,10))\n",
    "    plt.title(\"All Earthquake Affected Areas\")\n",
    "    \n",
    "    m = Basemap(projection='mill',llcrnrlat=-80,urcrnrlat=80, \n",
    "                llcrnrlon=-180,urcrnrlon=180,lat_ts=20,resolution='c')\n",
    "    \n",
    "    x, y = m(longitudes, latitudes)\n",
    "    m.plot(x, y, \"o\", markersize=2, color='blue', alpha=0.5)\n",
    "    m.drawcoastlines()\n",
    "    m.fillcontinents(color='coral',lake_color='aqua')\n",
    "    m.drawmapboundary()\n",
    "    m.drawcountries()\n",
    "    plt.savefig('earthquake_map.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    print(\"\\nMap saved as 'earthquake_map.png'\")\n",
    "except ImportError:\n",
    "    print(\"\\nBasemap not available, skipping visualization\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a664064",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ==================== PREPARE DATA ====================\n",
    "X = final_data[['Timestamp', 'Latitude', 'Longitude']]\n",
    "y = final_data[['Magnitude', 'Depth']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a780478a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Convert to numpy arrays and ensure float32 type\n",
    "X = X.values.astype('float32')\n",
    "y = y.values.astype('float32')\n",
    "\n",
    "print(\"\\nFeatures (X) shape:\", X.shape)\n",
    "print(\"Targets (y) shape:\", y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda3652c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Split data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(\"\\nTrain set:\", X_train.shape, y_train.shape)\n",
    "print(\"Test set:\", X_test.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3177b2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Normalize features for better neural network performance\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler_X = StandardScaler()\n",
    "X_train_scaled = scaler_X.fit_transform(X_train)\n",
    "X_test_scaled = scaler_X.transform(X_test)\n",
    "\n",
    "scaler_y = StandardScaler()\n",
    "y_train_scaled = scaler_y.fit_transform(y_train)\n",
    "y_test_scaled = scaler_y.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19855a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# ==================== RANDOM FOREST MODEL ====================\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"RANDOM FOREST REGRESSOR\")\n",
    "print(\"=\"*50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e343e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Basic Random Forest\n",
    "reg = RandomForestRegressor(random_state=42, n_estimators=100)\n",
    "reg.fit(X_train, y_train)\n",
    "y_pred_rf = reg.predict(X_test)\n",
    "\n",
    "print(\"\\nBasic Random Forest Results:\")\n",
    "print(f\"R² Score: {reg.score(X_test, y_test):.4f}\")\n",
    "print(f\"MSE: {mean_squared_error(y_test, y_pred_rf):.4f}\")\n",
    "print(f\"MAE: {mean_absolute_error(y_test, y_pred_rf):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc92a226",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# GridSearch for Random Forest (optional - can take time)\n",
    "print(\"\\nPerforming GridSearch for Random Forest...\")\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters = {'n_estimators': [50, 100, 200], 'max_depth': [10, 20, None]}\n",
    "grid_obj = GridSearchCV(reg, parameters, cv=3, n_jobs=-1, verbose=1)\n",
    "grid_fit = grid_obj.fit(X_train, y_train)\n",
    "best_fit = grid_fit.best_estimator_\n",
    "\n",
    "y_pred_rf_best = best_fit.predict(X_test)\n",
    "print(f\"\\nBest Random Forest Parameters: {grid_fit.best_params_}\")\n",
    "print(f\"Best R² Score: {best_fit.score(X_test, y_test):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b91bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# ==================== NEURAL NETWORK MODEL ====================\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"NEURAL NETWORK MODEL\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabc7cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# Build Neural Network Model\n",
    "def create_model(neurons=64, activation='relu', optimizer='adam', learning_rate=0.001):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons, activation=activation, input_shape=(3,)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(neurons//2, activation=activation))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(neurons//4, activation=activation))\n",
    "    model.add(Dense(2))  # Output layer for regression (Magnitude, Depth)\n",
    "    \n",
    "    if optimizer == 'adam':\n",
    "        opt = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    elif optimizer == 'sgd':\n",
    "        opt = keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "    else:\n",
    "        opt = optimizer\n",
    "    \n",
    "    model.compile(optimizer=opt, loss='mse', metrics=['mae'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8953c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Create and train model\n",
    "model = create_model(neurons=128, activation='relu', optimizer='adam', learning_rate=0.001)\n",
    "\n",
    "print(\"\\nModel Architecture:\")\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92249502",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Callbacks\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=0.00001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e409f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Train model\n",
    "print(\"\\nTraining Neural Network...\")\n",
    "history = model.fit(\n",
    "    X_train_scaled, y_train_scaled,\n",
    "    batch_size=32,\n",
    "    epochs=100,\n",
    "    verbose=1,\n",
    "    validation_data=(X_test_scaled, y_test_scaled),\n",
    "    callbacks=[early_stopping, reduce_lr]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56bf51cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Evaluate model\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"NEURAL NETWORK EVALUATION\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "[test_loss, test_mae] = model.evaluate(X_test_scaled, y_test_scaled, verbose=0)\n",
    "print(f\"\\nTest Loss (MSE): {test_loss:.4f}\")\n",
    "print(f\"Test MAE: {test_mae:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f499b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Make predictions\n",
    "y_pred_nn_scaled = model.predict(X_test_scaled)\n",
    "y_pred_nn = scaler_y.inverse_transform(y_pred_nn_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0a0e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Calculate metrics\n",
    "mse_nn = mean_squared_error(y_test, y_pred_nn)\n",
    "mae_nn = mean_absolute_error(y_test, y_pred_nn)\n",
    "r2_nn = r2_score(y_test, y_pred_nn)\n",
    "\n",
    "print(f\"\\nNeural Network Results (on original scale):\")\n",
    "print(f\"MSE: {mse_nn:.4f}\")\n",
    "print(f\"MAE: {mae_nn:.4f}\")\n",
    "print(f\"R² Score: {r2_nn:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb512e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# ==================== PLOT TRAINING HISTORY ====================\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "axes[0].plot(history.history['loss'], label='Training Loss')\n",
    "axes[0].plot(history.history['val_loss'], label='Validation Loss')\n",
    "axes[0].set_title('Model Loss')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Loss (MSE)')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True)\n",
    "\n",
    "axes[1].plot(history.history['mae'], label='Training MAE')\n",
    "axes[1].plot(history.history['val_mae'], label='Validation MAE')\n",
    "axes[1].set_title('Model MAE')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('MAE')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('training_history.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"\\nTraining history saved as 'training_history.png'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d562f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ==================== PREDICTION COMPARISON ====================\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Magnitude prediction\n",
    "axes[0].scatter(y_test[:, 0], y_pred_nn[:, 0], alpha=0.5)\n",
    "axes[0].plot([y_test[:, 0].min(), y_test[:, 0].max()], \n",
    "             [y_test[:, 0].min(), y_test[:, 0].max()], 'r--', lw=2)\n",
    "axes[0].set_xlabel('Actual Magnitude')\n",
    "axes[0].set_ylabel('Predicted Magnitude')\n",
    "axes[0].set_title('Magnitude Prediction')\n",
    "axes[0].grid(True)\n",
    "\n",
    "# Depth prediction\n",
    "axes[1].scatter(y_test[:, 1], y_pred_nn[:, 1], alpha=0.5)\n",
    "axes[1].plot([y_test[:, 1].min(), y_test[:, 1].max()], \n",
    "             [y_test[:, 1].min(), y_test[:, 1].max()], 'r--', lw=2)\n",
    "axes[1].set_xlabel('Actual Depth')\n",
    "axes[1].set_ylabel('Predicted Depth')\n",
    "axes[1].set_title('Depth Prediction')\n",
    "axes[1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('prediction_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"Prediction comparison saved as 'prediction_comparison.png'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5baecb86",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# ==================== SAVE MODELS ====================\n",
    "# Save Keras model\n",
    "model.save('earthquake_model.h5')\n",
    "print(\"\\nNeural Network model saved as 'earthquake_model.h5'\")\n",
    "\n",
    "# Save scalers\n",
    "import pickle\n",
    "with open('scaler_X.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler_X, f)\n",
    "with open('scaler_y.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler_y, f)\n",
    "print(\"Scalers saved as 'scaler_X.pkl' and 'scaler_y.pkl'\")\n",
    "\n",
    "# Save Random Forest model\n",
    "with open('random_forest_model.pkl', 'wb') as f:\n",
    "    pickle.dump(best_fit, f)\n",
    "print(\"Random Forest model saved as 'random_forest_model.pkl'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08cac339",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# ==================== PREDICTION FUNCTION ====================\n",
    "def predict_earthquake(timestamp, latitude, longitude):\n",
    "    \"\"\"\n",
    "    Predict earthquake magnitude and depth\n",
    "    \n",
    "    Parameters:\n",
    "    - timestamp: Unix timestamp\n",
    "    - latitude: Latitude value\n",
    "    - longitude: Longitude value\n",
    "    \n",
    "    Returns:\n",
    "    - magnitude: Predicted magnitude\n",
    "    - depth: Predicted depth in km\n",
    "    \"\"\"\n",
    "    # Prepare input\n",
    "    X_input = np.array([[timestamp, latitude, longitude]], dtype='float32')\n",
    "    \n",
    "    # Scale input\n",
    "    X_input_scaled = scaler_X.transform(X_input)\n",
    "    \n",
    "    # Predict\n",
    "    y_pred_scaled = model.predict(X_input_scaled, verbose=0)\n",
    "    y_pred = scaler_y.inverse_transform(y_pred_scaled)\n",
    "    \n",
    "    magnitude = y_pred[0][0]\n",
    "    depth = y_pred[0][1]\n",
    "    \n",
    "    return magnitude, depth\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99d322b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ==================== TEST PREDICTION ====================\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"EXAMPLE PREDICTION\")\n",
    "print(\"=\"*50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6983db",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Use a sample from test set\n",
    "sample_idx = 0\n",
    "sample_timestamp = X_test[sample_idx, 0]\n",
    "sample_lat = X_test[sample_idx, 1]\n",
    "sample_lon = X_test[sample_idx, 2]\n",
    "\n",
    "pred_mag, pred_depth = predict_earthquake(sample_timestamp, sample_lat, sample_lon)\n",
    "\n",
    "print(f\"\\nInput:\")\n",
    "print(f\"  Timestamp: {sample_timestamp}\")\n",
    "print(f\"  Latitude: {sample_lat:.4f}\")\n",
    "print(f\"  Longitude: {sample_lon:.4f}\")\n",
    "print(f\"\\nPrediction:\")\n",
    "print(f\"  Magnitude: {pred_mag:.2f}\")\n",
    "print(f\"  Depth: {pred_depth:.2f} km\")\n",
    "print(f\"\\nActual:\")\n",
    "print(f\"  Magnitude: {y_test[sample_idx, 0]:.2f}\")\n",
    "print(f\"  Depth: {y_test[sample_idx, 1]:.2f} km\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"EARTHQUAKE PREDICTION MODEL COMPLETE!\")\n",
    "print(\"=\"*50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "earthEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
